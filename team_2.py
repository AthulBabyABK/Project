# -*- coding: utf-8 -*-
"""Team 2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1nG2v85xX1ZTdD2dsXwxRogeJu_OGckAC
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

"""# Loading data"""

data = pd.read_excel(r'/content/A.xlsx')

data.shape

data.head()

data.info()

data = data.drop(['Name', 'Age', 'Special', 'GK diving', 'GK handling', 'GK kicking', 'GK positioning', 'GK reflexes'], axis =1)

data.columns

"""# Feature Engineering"""

# Movement = Acceleration,Sprint Speed,Agility,Reactions,Balance 
# ATTACKING = Crossing,Finishing,Heading Accuracy,Short Passing,Volleys
# SKILL = Dribbling,Curve,FK Accuracy,Long Passing,Ball Control
# POWER = Shot Power,Jumping,Stamina,Strength,Long Shots
# MENTALITY = Aggression,Interceptions,Positioning,Vision,Penalties,Composure
# DEFENDING = Defensive Awareness,Standing Tackle,Sliding Tackle

cols = ['Acceleration', 'Aggression', 'Agility', 'Ball control', 'Composure', 'Crossing', 'Curve', 'Dribbling', 'Finishing', 'Free kick accuracy', 'Heading accuracy', 'Interceptions', 'Jumping', 'Long passing', 'Long shots', 'Marking', 'Penalties', 'Positioning', 'Reactions', 'Short passing', 'Shot power', 'Sliding tackle', 'Sprint speed', 'Stamina', 'Standing tackle', 'Strength', 'Vision', 'Volleys']
data[cols] = data[cols].apply(pd.to_numeric, errors='coerce', axis=1)

Movement = data[['Acceleration', 'Agility', 'Reactions', 'Balance']]
Attacking = data[['Crossing', 'Finishing', 'Heading accuracy', 'Short passing', 'Volleys']]
Skill = data[['Dribbling', 'Curve', 'Free kick accuracy', 'Long passing', 'Ball control']]
Power = data[['Shot power', 'Jumping', 'Stamina', 'Strength', 'Long shots']]
Mentality = data[['Aggression', 'Interceptions', 'Positioning', 'Vision', 'Penalties', 'Composure']]
Defending = data[['Standing tackle', 'Sliding tackle']]

data.isna().sum()

sns.heatmap(Movement.corr(),annot=True)
plt.xticks(rotation=45)

sns.heatmap(Attacking.corr(),annot=True)
plt.xticks(rotation=45)

sns.heatmap(Power.corr(),annot=True)
plt.xticks(rotation=45)

sns.heatmap(Mentality.corr(),annot=True)
plt.xticks(rotation=45)

sns.heatmap(Skill.corr(),annot=True)
plt.xticks(rotation=45)

corrmatrix = data.corr()
plt.subplots(figsize=(20,8))
sns.heatmap(corrmatrix,vmin=0.4,vmax=0.9,annot=True,linewidths=0.2,cmap='YlGnBu')

#From above heatmaps, Agilty&balance, Acceleration&agility,finishing&volleys
#shotpower&longshots,position&penalties,dribbling&ball ctrl all are highly correlated.
#Hence, dropping the columns.

data = data.drop(['Agility', 'Balance', 'Finishing', 'Volleys', 'Shot power', 'Long shots', 'Positioning', 'Penalties', 'Dribbling', 'Interceptions', 'Ball control'], axis =1)

data.head()

data['Movement'] = data[['Acceleration', 'Reactions']].mean(axis=1)
data['Attacking'] = data[['Crossing', 'Heading accuracy', 'Short passing']].mean(axis=1)
data['Skill'] = data[['Curve', 'Free kick accuracy', 'Long passing']].mean(axis=1)
data['Power'] = data[['Jumping', 'Stamina', 'Strength']].mean(axis=1)
data['Mentality'] = data[['Aggression', 'Vision', 'Composure']].mean(axis=1)
data['Defending'] = data[['Standing tackle', 'Sliding tackle']].mean(axis=1)



data.columns

"""# Label Encoding"""

#from sklearn.preprocessing import LabelEncoder
#l=LabelEncoder()
#data['Segmentation']=l.fit_transform(data['N'])

"""# Splitting data"""

x = data.drop(['ID','Overall'], axis=1)
y = data['Overall']

from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test=train_test_split(x,y,random_state=42,test_size=0.2)

#from sklearn.preprocessing import StandardScaler
#scaler=StandardScaler()
#x_train=scaler.fit_transform(x_train)
#y_test=scaler.fit_transform(y_test)

"""# Using Random Forest Model to predict data"""

from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=42, test_size=0.2)

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, precision_score, recall_score 
forest = RandomForestClassifier()
model = forest.fit(x_train,y_train)
y_pred = model.predict(x_test)

sample = [[86,44,35,58,15,13,12,17,74,24,14,80,37,16,52,36,13,74,50,62,23,16.333333,61.333333,47.666667,14.500000]]
pr=model.predict(sample)
print(pr)

x_train.shape

x_test.shape

print(y_pred)

print('accuracy is',accuracy_score(y_test,y_pred))
print('Weighted F1-score: {:.2f}'.format(f1_score(y_test, y_pred, average='weighted')))
print('precition score' , precision_score(y_test,y_pred, average='weighted'))

confusion_matrix(y_test,y_pred)

print(classification_report(y_test,y_pred))

from sklearn.metrics import mean_squared_error

print('The MSE is: ', mean_squared_error(y_test,y_pred))

"""# Regression"""

from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=42, test_size=0.2)

from sklearn.linear_model import LogisticRegression
logit_model = LogisticRegression()
logit_model.fit(x_train, y_train)
y_pred=logit_model.predict(x_test)

print(y_pred)

print('accuracy is',accuracy_score(y_test,y_pred))
print('Weighted F1-score: {:.2f}'.format(f1_score(y_test, y_pred, average='weighted')))
print('precition score' , precision_score(y_test,y_pred, average='weighted'))

"""# DecisionTree"""

from sklearn.tree import DecisionTreeClassifier

data_model = DecisionTreeClassifier()

logit_model.fit(x_train,y_train)

y_pred=logit_model.predict(x_test)

from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score

print(accuracy_score(y_test,y_pred))

print('accuracy is',accuracy_score(y_test,y_pred))
print('Weighted F1-score: {:.2f}'.format(f1_score(y_test, y_pred, average='weighted')))
print('precition score' , precision_score(y_test,y_pred, average='weighted'))

"""# KNN"""

from sklearn.ensemble import RandomForestClassifier
rf=RandomForestClassifier()
rf.fit(x_train,y_train)
y_pred=rf.predict(x_test)

print("Accuracy is:", accuracy_score(y_test, y_pred))

print('accuracy is',accuracy_score(y_test,y_pred))
print('Weighted F1-score: {:.2f}'.format(f1_score(y_test, y_pred, average='weighted')))
print('precition score' , precision_score(y_test,y_pred, average='weighted'))

confusion_matrix(y_test, y_pred)

"""# SVM"""

from sklearn.svm import SVC
svm_linear=SVC(kernel='linear')
svm_linear.fit(x_train, y_train)
y_pred=svm_linear.predict(x_test)

print('accuracy is',accuracy_score(y_test,y_pred))
print('Weighted F1-score: {:.2f}'.format(f1_score(y_test, y_pred, average='weighted')))
print('precition score' , precision_score(y_test,y_pred, average='weighted'))

"""# Gradient Boosting"""

from sklearn.ensemble import GradientBoostingClassifier
gb=GradientBoostingClassifier()
gb.fit(x_train,y_train)

print('accuracy is',accuracy_score(y_test,y_pred))
print('Weighted F1-score: {:.2f}'.format(f1_score(y_test, y_pred, average='weighted')))
print('precition score' , precision_score(y_test,y_pred, average='weighted'))

"""# XGB"""

from xgboost import XGBClassifier
xgb=XGBClassifier()
model1=xgb.fit(x_train,y_train)

y_pred=model1.predict(x_test)

print('accuracy is',accuracy_score(y_test,y_pred))
print('Weighted F1-score: {:.2f}'.format(f1_score(y_test, y_pred, average='weighted')))
print('precition score' , precision_score(y_test,y_pred, average='weighted'))

y_pred

x_test.iloc[0,:]

